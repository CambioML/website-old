<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="Data Labeling &amp; Annotation" href="data_labeling_annotation.html" /><link rel="prev" title="Comparing Models" href="model_comparison.html" />

    <!-- Generated with Sphinx 7.1.2 and Furo 2023.07.26 -->
        <title>Reinforcement Learning with Human Feedback - pykoi 0.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=362ab14a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css?v=4a2a2a4c" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --color-admonition-title--note: #00ebc7;
  --color-admonition-title-background--note: #a2fff1;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">pykoi 0.0.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tour.html">Quick Tour</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Features</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="data_collection_feedback.html">Collecting User Feedback via a Chat Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_comparison.html">Comparing Models</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Reinforcement Learning with Human Feedback</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_labeling_annotation.html">Data Labeling &amp; Annotation</a></li>
<li class="toctree-l1"><a class="reference internal" href="knowledge_retrieval.html">Finetuning &amp; Knowledge Retrieval</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="modules.html">pykoi</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of pykoi</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="pykoi.html">pykoi package</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of pykoi package</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pykoi.chat.html">pykoi.chat package</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of pykoi.chat package</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="pykoi.chat.db.html">pykoi.chat.db package</a></li>
<li class="toctree-l4"><a class="reference internal" href="pykoi.chat.llm.html">pykoi.chat.llm package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pykoi.rlhf.html">pykoi.rlhf package</a></li>
<li class="toctree-l3"><a class="reference internal" href="pykoi.component.html">pykoi.component package</a></li>
<li class="toctree-l3"><a class="reference internal" href="pykoi.interactives.html">pykoi.interactives package</a></li>
<li class="toctree-l3"><a class="reference internal" href="pykoi.telemetry.html">pykoi.telemetry package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="tests.html">tests package</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of tests package</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4 has-children"><a class="reference internal" href="tests.chat.html">tests.chat package</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of tests.chat package</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="tests.chat.db.html">tests.chat.db package</a></li>
<li class="toctree-l5"><a class="reference internal" href="tests.chat.llm.html">tests.chat.llm package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tests.component.html">tests.component package</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Social</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community.html">Community</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="reinforcement-learning-with-human-feedback">
<h1>Reinforcement Learning with Human Feedback<a class="headerlink" href="#reinforcement-learning-with-human-feedback" title="Permalink to this heading">#</a></h1>
<p>Reinforcement Learning with Human Feedback (RLHF) is a unique training paradigm that blends reinforcement learning and human-in-the-loop training. The central idea is to use humans’ evaluative feedback to refine a model’s decision-making ability and guide the learning process towards desired outcomes. Researchers from <a class="reference external" href="https://www.deepmind.com/blog/learning-through-human-feedback">Deepmind</a>, <a class="reference external" href="https://openai.com/research/learning-from-human-preferences">OpenAI</a> and <a class="reference external" href="https://arxiv.org/pdf/2307.09288.pdf">Meta Llama2</a> all show RLHF is the game changer for large language models (LLMs) training.</p>
<p>The following figure shows the model training pipeline of RLHF.</p>
<a class="reference internal image-reference" href="_images/rlhf_flow.svg"><img alt="optional alt text" class="align-center" height="338" src="_images/rlhf_flow.svg" width="570" /></a>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="f1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>source: OpenAI.</p>
</aside>
</aside>
<p>RLHF contains three steps:</p>
<ul class="simple">
<li><p>Step 1: Supervised Finetuning: gather a dataset of human-generated responses. This dataset is then used to train our baseline models using supervised learning.</p></li>
<li><p>Step 2: Reward Finetuning: assemble another dataset featuring human-labelled comparisons between multiple outputs from the model on different prompts. Then, a reward model (RM) is trained on this dataset to classify the output preferred by our labelers.</p></li>
<li><p>Step 3: Reinforcement Learning: use this RM as a reward function and fine-tune our GPT-3 policy to optimize this reward using RL algorithms such as the Proximal Policy Optimization (PPO) algorithm or the Direct Preference Optimization (DPO) algorithm.</p></li>
</ul>
<p>pykoi allows you to easily finetune your model on the datasets you collected via <span class="xref std std-doc">data_collection_feedback.rst</span> and <span class="xref std std-doc">data_collection_comparison.rst</span>.</p>
<section id="step-1-supervised-finetuning">
<h2>Step 1: Supervised Finetuning<a class="headerlink" href="#step-1-supervised-finetuning" title="Permalink to this heading">#</a></h2>
<p>In this step, we use the dataset collected via <span class="xref std std-doc">data_collection_feedback.rst</span> to train a baseline model using supervised learning. First, we import pykoi and load data from the local database.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pykoi</span>

<span class="c1"># get data from local database</span>
<span class="n">qa_database</span> <span class="o">=</span> <span class="n">pykoi</span><span class="o">.</span><span class="n">QuestionAnswerDatabase</span><span class="p">()</span>
<span class="n">my_data_pd</span> <span class="o">=</span> <span class="n">qa_database</span><span class="o">.</span><span class="n">retrieve_all_question_answers_as_pandas</span><span class="p">()</span>

<span class="c1"># analyze the data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">my_data_pd</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;My local database has </span><span class="si">{}</span><span class="s2"> samples in total&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">my_data_pd</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
<p>Then, we can use the data to train a baseline model using supervised learning.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># run supervised finetuning</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">pykoi</span><span class="o">.</span><span class="n">RLHFConfig</span><span class="p">(</span><span class="n">base_model_path</span><span class="o">=</span><span class="s2">&quot;meta-llama/Llama-2-7b-hf&quot;</span><span class="p">,</span>
                          <span class="n">dataset_type</span><span class="o">=</span><span class="s2">&quot;local_db&quot;</span><span class="p">)</span>
<span class="n">rlhf_step1_sft</span> <span class="o">=</span> <span class="n">pykoi</span><span class="o">.</span><span class="n">SupervisedFinetuning</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">rlhf_step1_sft</span><span class="o">.</span><span class="n">train_and_save</span><span class="p">(</span><span class="s2">&quot;./models/rlhf_step1_sft&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-2-reward-finetuning">
<h2>Step 2: Reward Finetuning<a class="headerlink" href="#step-2-reward-finetuning" title="Permalink to this heading">#</a></h2>
<p>After we trained a baseline model, we can use the dataset collected via <span class="xref std std-doc">data_collection_comparison.rst</span> to train a reward model (RM) using supervised learning. First, we import pykoi and load data from the local database.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pykoi</span>

<span class="c1"># get data from local database</span>
<span class="n">ranking_database</span> <span class="o">=</span> <span class="n">pykoi</span><span class="o">.</span><span class="n">RankingDatabase</span><span class="p">()</span>
<span class="n">my_data_pd</span> <span class="o">=</span> <span class="n">ranking_database</span><span class="o">.</span><span class="n">retrieve_all_question_answers_as_pandas</span><span class="p">()</span>

<span class="c1"># analyze the data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">my_data_pd</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;My local database has </span><span class="si">{}</span><span class="s2"> samples in total&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">my_data_pd</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
<p>Then, we can use the data to train a reward model (RM) using supervised learning.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># run reward model finetuning</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">pykoi</span><span class="o">.</span><span class="n">RLHFConfig</span><span class="p">()</span>
<span class="n">rlhf_step2_rft</span> <span class="o">=</span> <span class="n">pykoi</span><span class="o">.</span><span class="n">RewardFinetuning</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">rlhf_step2_rft</span><span class="o">.</span><span class="n">train_and_save</span><span class="p">(</span><span class="s2">&quot;./models/rlhf_step2_rw&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-3-reinforcement-learning">
<h2>Step 3: Reinforcement Learning<a class="headerlink" href="#step-3-reinforcement-learning" title="Permalink to this heading">#</a></h2>
<p>After we trained a reward model (RM), we can use the RM as a reward function and fine-tune our GPT-3 policy to optimize this reward using RL algorithms such as the Proximal Policy Optimization (PPO) algorithm or the Direct Preference Optimization (DPO) algorithm. First, we import pykoi and define the config.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pykoi</span>

<span class="c1"># use huggingface sft and reward model</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">pykoi</span><span class="o">.</span><span class="n">RLHFConfig</span><span class="p">(</span>
   <span class="n">base_model_path</span><span class="o">=</span><span class="s2">&quot;meta-llama/Llama-2-7b-hf&quot;</span><span class="p">,</span>
   <span class="n">reward_model_path</span><span class="o">=</span><span class="s2">&quot;goldmermaid/rlhf_reward_model&quot;</span><span class="p">,</span>
   <span class="n">dataset_type</span><span class="o">=</span><span class="s2">&quot;huggingface&quot;</span><span class="p">,</span>
   <span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;goldmermaid/stack_exchange_rank_10k_dataset&quot;</span><span class="p">,</span>
   <span class="n">dataset_subset_rl</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then, we can use the config to train a policy using RL.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rlhf_step3_rl</span> <span class="o">=</span> <span class="n">pykoi</span><span class="o">.</span><span class="n">RLFinetuning</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">rlhf_step3_rl</span><span class="o">.</span><span class="n">train_and_save</span><span class="p">(</span><span class="s2">&quot;./models/rlhf_step3_rl&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This project is under active development.</p>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="data_labeling_annotation.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Data Labeling &amp; Annotation</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="model_comparison.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Comparing Models</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, CambioML
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/CambioML/pykoi" aria-label="Website">
                <svg width="447" height="425" viewBox="0 0 447 425" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M436 212.5C436 323.269 341.39 414 223.5 414C105.61 414 11 323.269 11 212.5C11 101.731 105.61 11 223.5 11C341.39 11 436 101.731 436 212.5Z" stroke="#393939" stroke-width="22"/>
                    <rect x="118" y="148" width="40" height="42.2633" rx="20" fill="#393939"/>
                    <rect x="210" y="148" width="40" height="42.2633" rx="20" fill="#393939"/>
                    <rect x="302" y="148" width="40" height="40" rx="20" fill="#393939"/>
                    <path d="M184.646 212C184.646 212 171.914 285 259.488 285C347.062 285 357 212 357 212" stroke="#393939" stroke-width="22" stroke-linecap="round"/>
                    <path d="M97.6462 212C97.6462 212 84.9137 285 172.488 285C260.062 285 270 212 270 212" stroke="#393939" stroke-width="22" stroke-linecap="round"/>
                </svg>
            </a>
              <a class="muted-link " href="https://github.com/CambioML/pykoi" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Reinforcement Learning with Human Feedback</a><ul>
<li><a class="reference internal" href="#step-1-supervised-finetuning">Step 1: Supervised Finetuning</a></li>
<li><a class="reference internal" href="#step-2-reward-finetuning">Step 2: Reward Finetuning</a></li>
<li><a class="reference internal" href="#step-3-reinforcement-learning">Step 3: Reinforcement Learning</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=525cde36"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="_static/scripts/furo.js?v=32e29ea5"></script>
    </body>
</html>